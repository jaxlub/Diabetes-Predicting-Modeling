---
title: ""
author: "Jax Lubkowitz"
format: html
editor: visual
---

# Abstract
- what is diabetes?
- what is dataset?
- what is goal?
- what are we showing?

## Background & Relavance

Find sources?

Questions of Interest - 
- What techniques best model the relationship between various predictors and diabetes outcome?
- What characteristics can be used to predict diabetes outcome?


## Tidying 
  The data set had a large amount of 0 values for things such as skin thickness. Upon further investigation it appeared that null values in the data set had been filled in with 0's. When modeling this could cause serious skews in our results. To prevent this I removed all 0 values in categories where they had been applied as null (ie 0 pregnancies makes sense but having 0 BMI is just a null value). The one problem with this tack is it limits the amount of data available. Initially the data set had 768 instances but after filtering all null Glucose, Blood Pressure, Skin Thickness, Insulin and BMI values the data set was left with 392 instances. 


## Model backgrounds
LOG - QDA - LDA - Naive Bayes - Tree

# Data Exploration
## Histograms
Glucose and Insulin r instresting
show visuals 

```{r}
library(tidyverse)
library(gridExtra)
library(tidymodels)
remotes::install_github("grantmcdermott/parttree")
library(parttree)
library(splitTools) # create_folds
set.seed(123)
data <- read.csv('/Users/jaxlub/Downloads/diabetes.csv')
data <- data |> 
  filter(Glucose != 0) |>
  filter(BloodPressure != 0) |>
  filter(SkinThickness != 0) |>
  filter(Insulin != 0) |>
  filter(BMI != 0)
data_pos <- data |> filter(Outcome == 1) 
data_neg <- data |> filter(Outcome == 0) 
```

```{r}
ggplot(data = data_neg, aes(x = Insulin)) +
  geom_histogram(fill = "cornflowerblue", color = "black") + 
  labs(title = "Insulin Distribution in Non-Diabetic Patients") + 
  theme_minimal(base_size = 20)
ggplot(data = data_pos, aes(x = Insulin)) +
  geom_histogram(fill = "firebrick1", color = "black") + 
  labs(title = "Insulin Distribution in Diabetic Patients") + 
  theme_minimal(base_size = 20)
```


## Logistic Model
```{r}
    full.log <- glm(Outcome ~ ., data = data, family = binomial)
    summary(full.log)

    folds <- create_folds(data$Outcome, k = 5)
    error <- rep(0, 5)
    i <- 1
    for (train in folds) {
      model <- glm(Outcome ~ ., data = data[train,], family = binomial)
      probabilities <- predict(model, newdata = data[-train,], type = "response")
      predictions <- ifelse(probabilities > 0.5, "1", "0")
      error[i] <- mean(predictions != data[-train,]$Outcome)
      i <- i + 1
    }
    
    text <- print(paste0("Train Error Rate: ", round(mean(error), digits = 5)))
```


## Parttree Model
```{r}
data$Outcome = as.factor(data$Outcome)

## Build our tree using parsnip (but with rpart as the model engine)
tree =
  decision_tree() |>
  set_engine("rpart") |>
  set_mode("classification") |>
  fit(Outcome ~ BMI + Age, data = data)


## Plot the data and model partitions
data |>
  ggplot(aes(x = BMI, y = Age)) +
  geom_jitter(aes(colour = Outcome), alpha = 0.7) +
  geom_parttree(data = tree, aes(fill = Outcome), alpha = 0.1) +
  labs(x = "BMI",
       y = "Age",
       title = "Classification Areas of Diabetes") +
  theme_classic(base_size = 24)
```




## Scatter plots 


## Discuss Shiny App

# Conclusion


